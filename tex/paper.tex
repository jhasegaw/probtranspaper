\documentclass[10pt,final,letterpaper,twocolumn,journal]{IEEEtran}
\bibliographystyle{plain}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\usepackage[affil-it]{authblk}
\usepackage{url}
\usepackage{tabularx}
\usepackage{tikz}
\usepackage{cite}
\usepackage{tipa}\newcommand{\ipa}[1]{\textipa{#1}}
\usetikzlibrary{positioning,shadows,arrows,shapes,calc}
\newcommand{\mytikzscale}{0.55}

\title{ASR for Under-Resourced Languages from Probabilistic Transcription}

\author{Mark Hasegawa-Johnson$^1$,~\IEEEmembership{Senior~Member,~IEEE}
  Preethi Jyothi$^1$,~\IEEEmembership{Member,~IEEE}
  Daniel McCloy$^2$,
  Majid Mirbagheri$^2$,
  Giovanni di Liberto$^3$,
  Amit Das$^1$,~\IEEEmembership{Student~Member,~IEEE}
  Bradley Ekin$^2$,~\IEEEmembership{Student~Member,~IEEE}
  Chunxi Liu$^4$,
  Vimal Manohar$^4$,~\IEEEmembership{Student~Member,~IEEE}
  Hao Tang$^5$,
  Edmund C. Lalor$^3$,
  Nancy F.\ Chen$^6$,~\IEEEmembership{Senior~Member,~IEEE}
  Paul Hager$^7$,
  Tyler Kekona$^2$,
  Rose Sloan$^8$,
  and Adrian KC Lee$^2$~\IEEEmembership{Member,~IEEE}
}
\affil{1. University of Illinois, 2. University of Washington,
  3. Trinity College, Dublin, 4. Johns Hopkins University, 5. Toyota
  Technological Institute Chicago, 6. Institute for Infocomm Research,
  7. MIT, 8. Columbia University}

\markboth{IEEE Transactions on Audio, Speech and Language}
{Hasegawa-Johnson \MakeLowercase{\textit{et al.}}: ASR for Under-Resourced Languages from Probabilistic Transcription}

\begin{document}
\maketitle

\begin{abstract}
\input{s0_abstract.tex}
\end{abstract}

\begin{IEEEkeywords}
Automatic speech recognition, Under-resourced languages, Mismatched crowdsourcing, EEG
\end{IEEEkeywords}

\ifCLASSOPTIONpeerreview
\begin{center} \bfseries EDICS Category: SPE-MULT \end{center}
\fi
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{s1_intro.tex}

\input{s2_background.tex}
\input{s2_background_urasr.tex}
\input{s2_background_mismatch.tex}
\input{s2_background_eeg.tex}

\input{s4_probtrans.tex}
\input{s4_probtrans_selftrain.tex}
\input{s4_probtrans_mc.tex}
\input{s4_probtrans_eeg.tex}

\input{s3_training.tex}
\input{s3_training_ml.tex}
\input{s3_training_viterbi.tex}
\input{s3_training_lm.tex}
\input{s3_training_map.tex}
\input{s3_training_dnn.tex}

% Section 5: Audio Data and Mismatched Crowdsourcing
\input{s5_methods_data.tex}
\input{s5_methods_mc.tex}
\input{s6_mc.tex}

% Section 6: EEG methods and results
\input{s5_methods_eeg.tex}
\input{s6_results_eeg.tex}

% Section 7: ASR methods and results
\input{s5_methods.tex}
\input{s5_methods_mlbaseline.tex}
\input{s5_pt_adapt.tex}
\input{s6_results_mlbaseline.tex}
%\input{s6_results.tex}
\input{s6_results_asr.tex}

\input{s7_discussion.tex}
\input{s8_conclusions.tex}
\input{s9_acknowledgments.tex}

\bibliography{../bib/references,../bib/refs}

\input{s10_biographies.tex}

\end{document}

