\subsection{Mismatched Crowdsourcing}
\label{sec:MC}

\begin{figure}[b!]\setlength{\textfloatsep}{3mm}
\begin{center}
  \tikzstyle{pre}=[<-,shorten <=3pt,>=stealth',thick, draw=black]
  \tikzstyle{post}=[->,shorten >=3pt,>=stealth',thick, draw=black]
  \begin{tikzpicture}[
      scale=\mytikzscale,
      boxed/.style={rectangle,thick, draw=black, text=black, rounded corners=1mm, text centered, text width=5cm},
      state/.style={circle,thick, draw=black, text=black, text width=0.25cm},
      open/.style={text=black, text centered},
      every node/.style={transform shape}
    ]
    \node[open] (n0) at (1,0) {\begin{tabular}{c}$T$=Mismatched\\Transcripts\\\hline trabiza\\ta peesome\\ta pisha\\chah peesh um\\shapisha\\sabeesham\\chapiser\\some pizza\end{tabular}};
    \node[boxed] (n1) at (6,0) {\begin{tabular}{c}$\rho(\lambda|T)$\\\hline\vspace{3cm}\end{tabular}} edge[pre] (n0);
    \node[state] (g0) at (4,-0.25) {};
    \node[state] (g1) at (6,-0.25) {};
    \node (g2) at (8,-0.25) {\ldots};
    \draw[post] (g0) -- (4.25,0.75) -- (5.75,0.75) -- (g1);
    \node at (5,1) {$<$t$>$$/0.4$};
    \draw[post] (g0) -- (g1);
    \node at (5,0) {$<$ch$>$$/0.4$};
    \draw[post] (g0) -- (4.25,-1.25) -- (5.75,-1.25) -- (g1);
    \node at (5,-1) {$<$s$>$$/0.2$};
    \draw[post] (g1) -- (g2);
    \node at (7,0) {$<$a$>$$/1.0$};
    \node[boxed] (n2) at (12,0) {\begin{tabular}{c}$\rho(\phi|T)$\\\hline\vspace*{3cm}\end{tabular}} edge[pre] (n1);
    \node[state] (g10) at (10,-0.25) {};
    \node[state] (g11) at (12,-0.25) {};
    \node (g12) at (14,-0.25) {\ldots};
    \draw[post] (g10) -- (10.25,0.75) -- (11.75,0.75) -- (g11);
    \node at (11,1) {\ipa{[t]}$/0.4$};
    \draw[post] (g10) -- (g11);
    \node at (11,0) {\ipa{[tS]}$/0.4$};
    \draw[post] (g10) -- (10.25,-1.25) -- (11.75,-1.25) -- (g11);
    \node at (11,-1) {\ipa{[s]}$/0.2$};
    \draw[post] (g11) -- (g12);
    \node at (13,0) {\ipa{[A]}$/1.0$};
  \end{tikzpicture}\\
\end{center}
\setlength{\abovecaptionskip}{0pt}
\caption{Probabilistic transcription from mismatched crowdsourcing:
  Transcripts $T$ are filtered to remove outliers, and merged to
  create a confusion network over orthographic symbols,
  $\rho(\lambda|T)$, from which the probabilistic transcript
  $\rho(\phi|T)$ is inferred. Example shown: Swahili speech,
  English-speaking transcribers.  Symbols in $<$$>$ are graphemes,
  symbols in $[]$ are phones, numbers are probabilities.}
\label{fig:mcmethods}
\end{figure}

The second set of PTs was computed by sending audio in the target
language to non-speakers of the target language, and asking them to
write what they hear.  It would be preferable to recruit transcribers
who speak a language with predictable orthography, but since
transcribers in those languages were more expensive, this
experiment instead recruited transcribers who speak American English.
Denote using $T$ the set of mismatched
transcripts produced by these English-speaking crowd workers,
which we wish to interpret as a pmf over
target-language phone sequences, $\rho(\phi|T)$.  As an intermediate
step, prior work~\cite{JHJ15b} developed techniques
to merge texts into a confusion network
$\rho(\lambda|T)$ over representative transcripts in the
annotation-language orthography (Fig.~\ref{fig:mcmethods}).
%Formation of
%$\rho(\lambda|T)$ involves data filtering to remove outliers (based on
%pair-wise string edit distance among transcripts), expansion of the
%orthography to an alphabet that includes
%single-character symbols for digraphs and sequences commonly used to represent
%single phonemes in English orthography ($<$ai, ay, ee, oo, ou, aw, ow,
%bh, ch, dh, gh, jh, kh, ph, sh, th, wh, zh, ck$>$, and any vowel followed by
%a word-final silent $<$e$>$), and a weighted
%voting scheme in which the weight of each transcript is proportional
%to the frequency with which it matches the other transcripts.

Once transcripts have
been aligned and filtered to create the orthographic confusion network
$\rho(\lambda|T)$, they are then translated into a distribution over
phone transcripts according to:
\begin{align}
  \rho(\phi|T) 
%  &=\sum_{\lambda} \rho(\phi|\lambda,T) \rho(\lambda|T) \notag \\
  &\approx \max_{\lambda}  \rho(\phi|\lambda) \rho(\lambda|T) \notag \\
  &= \max_{\lambda}  \left(\frac{\rho(\lambda|\phi)}{\rho(\lambda)}
  \rho(\phi)\right) \rho(\lambda|T) 
\label{eq:PT}
\end{align}
The terms other than $\rho(\lambda|T)$ in Equation~(\ref{eq:PT}) are
estimated as follows.  $\rho(\lambda)$ is modeled using a unigram
prior over the letter sequences in $\lambda$.  $\rho(\phi)$ is modeled
using either a cross-lingual phone unigram, a
language-constrained cross-lingual unigram (the cross-lingual
unigram, constrained to take values from the phone set of the target
language), or a language-specific phone bigram
$\rho(\phi)=\prod_{m=1}^M \rho(\phi_m|\phi_{m-1})$.
Sec.~\ref{sec:trainwithlm} describes an algorithm for training the
phone bigram without using proscribed test-language resources;
Sec.~\ref{sec:data} lists the PT accuracies achieved using each of
these three approaches.
$\rho(\lambda|\phi)$ is called the misperception G2P, as it maps to
graphemes in the annotation language, $\lambda$, fsrom phones in the
utterance language, $\phi$.  Section~\ref{sec:eegchanmod} describes
methods that decompose $\rho(\lambda|\phi)$ into separate
misperception and G2P transducers, but it can also be trained directly
using
representative transcripts $\lambda$ (and their
corresponding native transcripts) for speech {\em in languages other
  than the target language}.
The model learned in this way is essentially
a machine translation model, which translates between graphemes in
the annotation language ($\lambda$) to phonemes in any possible
utterance language ($\phi$).
We assume that misperceptions depend more
heavily on the annotation language than on the utterance language, and
that therefore a model $\rho(\lambda|\phi)$ trained using a universal
phone set for $\phi$ is also a good model of $\rho(\lambda|\phi)$ for
the target language. Note that, while this assumption is not entirely
accurate, it is necessitated by the requirement that no native
transcripts in the target language can be used in building any part
of our system.

