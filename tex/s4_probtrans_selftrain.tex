\subsection{Self-Training}
\label{sec:selftraining}

The first set of PTs is computed using NN self-training.
The Kaldi toolkit~\cite{Kaldi2011} is first used to train a
cross-lingual baseline ASR, using training data drawn from six
languages not including the target language.  The goal of
self-training, then, is to adapt the NN to a database containing
$L$ speech waveforms in the target language, each represented by
acoustic feature matrix $x^\ell =[x_1^\ell,\ldots,x_T^\ell]$, where
$x_t^\ell$ is an acoustic feature vector.  The feature matrix $x^\ell$
represents an utterance of an unknown phone transcript
$\phi^\ell=[\phi_1^\ell,\ldots,\phi_M^\ell]$ which, if known, would
determine the sequence but not the durations of senones (HMM states)
$s^\ell =[s_1^\ell,\ldots,s_T^\ell]$.

The feature matrix $x^\ell$ is decoded using the cross-lingual
baseline ASR, generating a phone lattice output.  Using scripts
provided by previous experiments~\cite{vesely2013-semi}, the phone
lattice is interpreted as a set of posterior senone probabilities
$\rho(s_t^\ell|x_t^\ell)$ for each frame, and the senone posteriors
serve as targets for re-estimating the NN weights.
Experiments using other datasets found that self-training
should use best-path alignment to specify a binary target for NN
training~\cite{vesely2013-semi}, but, apparently because of
differences in the adaptation set between our experiments and previous
work, we achieve better performance using real-valued targets.
As in previous work, senones with a posterior probability
below 0.7 were removed from the training set, thus the training target
was a number between 0.7 and 1.0.
