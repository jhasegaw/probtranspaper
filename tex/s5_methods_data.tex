%\subsection{Data}
\section{Audio Data and Mismatched Crowdsourcing}
\label{sec:data}

Speech data were extracted from publicly available podcasts~\cite{SBS}
hosted in 68 different languages.  In order to generate test corpora
(in which it is possible to measure phone error rate), advertisements
were posted at the University of Illinois seeking native speakers
willing to transcribe speech in any of these 68 languages.  Of the ten
transcribers who responded, six people were each able to complete one
hour of speech transcription (the other four dropped out).  One
additional language was transcribed by workers recruited at $I^2R$ in
Singapore, yielding a total of seven languages with native
transcripts suitable for testing an ASR: Arabic (arb), Cantonese
(yue), Dutch (nld), Hungarian (hun), Mandarin (cmn), Swahili (swh) and
Urdu (urd).
{\color{blue} It is desirable to test the ideas in this paper with corpora larger
than one hour per language, but larger corpora involve problems
orthogonal to the purposes of this paper, e.g., the Babel corpora
contain telephone speech, and therefore contain far more acoustic
background noise than the podcast corpora used in this paper.}

The podcasts contain utterances interspersed with segments of music
and English. A GMM-based language identification system was
developed in order to isolate
regions that correspond mostly to the target language, which
were then split into 5-second
segments to enable easy labeling by the native transcribers.
%and more importantly to allow for the collection of mismatched
%transcripts that required the speech segments to be short. To
%further check that only speech clips in the target language were
%retained, the
Native transcribers were asked to omit any 5-second clips that
contained significant music, noise, English, or speech from multiple
speakers. Resulting transcripts covered 45 minutes of speech in Urdu
and 1 hour of speech in the remaining six languages. The orthographic
transcripts for these clips were then converted into phonemic
transcripts using language-specific dictionaries and G2P mappings.
{\color{blue} In order to make it possible to transfer ASR from
  training languages (which have native transcripts) to a test
  language (that has no native transcripts), the phone set must be
  standardized across all languages; for this purpose, the phone set
  was based on the international phonetic alphabet
  (IPA;~\cite{ipa1993}).  Similarly, in order to transfer ASR from
  training languages to a test language, the training transcriptions
  must be converted to phonemes using a grapheme-to-phoneme transducer
  (G2P).  G2Ps were therefore assumed to be available in all training
  languages, but not in the test language.  Since these G2Ps are only
  used for training and not test languages, five of them (Arabic,
  Dutch, Hungarian, Cantonese and Mandarin) were trained using lexical
  resources, and only two (Urdu and Swahili) were constructed using
  the zero-resource knowledge-based method described in
  Sec.~\ref{sec:trainwithlm}.}  English words in each transcript are
identified and converted to phones with an English G2P trained using
CMUdict~\cite{Lenzo1995}, then other words are converted into phonetic
transcripts using language-dependent dictionaries and G2Ps.
%We take the canonical pronunciation of a word if the word
%appears in a lexicon,
%otherwise estimate the word's pronunciation using a G2P.
The Arabic dictionary is from the Qatari Arabic Corpus~\cite{Elmahdy14},
the Dutch dictionary is from CELEX v2~\cite{Baayen96},
the Hungarian dictionary was provided by BUT~\cite{Grezl14},
the Cantonese dictionary is from $I^2R$,
and the Mandarin dictionary is from CALLHOME~\cite{LDC96}.
For
each language, we chose a random 40/10/10 minutes split into training,
development and evaluation sets.
%Table~\ref{tab:data} describes the
%resulting training, development and evaluation sets.
%\begin{table}[t]
%\centering
%\begin{tabular}{|c||ccc|}\hline
%Language  & \multicolumn{3}{c|}{Speech (\# phones)}\\
%(ISO 639-3) & Train & Dev & Eval \\ \hline\hline
%arb & 32486 & 8208 & 8191 \\
%yue & 32693 & 6860 & 8638 \\
%nld & 27314 & 6943 & 6582 \\
%hun & 29461 & 7873 & 7474 \\
%cmn & 29461 & 8244 & 7035 \\
%swh & 28571 & 7658 & 7441 \\
%urd & 21275 & 5808 & 3689 \\\hline
%\end{tabular}
%\vspace*{1mm}
%\caption{Data statistics, seven languages, \# 
%phones in the train/dev/eval sets.}
%\label{tab:data}
%\end{table}
