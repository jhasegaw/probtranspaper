\subsection{Data}
\label{sec:data}

Speech data were extracted from publicly available podcasts~\cite{SBS}
hosted in 68 different languages.  In order to generate test corpora
(in which it is possible to measure phone error rate), advertisements
were posted at the University of Illinois seeking native speakers
willing to transcribe speech in any of these 68 languages.  Of the ten
transcribers who responded, six people were each able to complete one
hour of speech transcription (the other four dropped out).  One
additional language was transcribed by workers recruited at $I^2R$ in
Singapore, yielding a total of seven languages with native
transcripts suitable for testing an ASR: Arabic (arb), Cantonese
(yue), Dutch (nld), Hungarian (hun), Mandarin (cmn), Swahili (swh) and
Urdu (urd).
It is desirable to test the ideas in this paper with corpora larger
than one hour per language, but larger corpora involve problems
orthogonal to the purposes of this paper, e.g., the Babel corpora
are telephone speech, and therefore contain far more acoustic
background noise than the podcast corpora used in this paper.

The podcasts contain utterances interspersed with segments of music
and English. A GMM-based language identification system was
developed in order to isolate
regions that correspond mostly to the target language, which
were then split into 5-second
segments to enable easy labeling by the native transcribers.
%and more importantly to allow for the collection of mismatched
%transcripts that required the speech segments to be short. To
%further check that only speech clips in the target language were
%retained, the
Native transcribers were asked to omit any 5-second
clips that contained significant music, noise, English,
or speech from multiple speakers. Resulting transcripts
covered 45 minutes of speech in Urdu and 1
hour of speech in the remaining six languages. The orthographic
transcripts for these clips were then converted into phonemic
transcripts using language-specific dictionaries and G2P mappings
(these resources are detailed in Section~\ref{sec:mlbaseline}). For
each language, we chose a random 40/10/10 minutes split into training,
development and evaluation sets.
%Table~\ref{tab:data} describes the
%resulting training, development and evaluation sets.
%\begin{table}[t]
%\centering
%\begin{tabular}{|c||ccc|}\hline
%Language  & \multicolumn{3}{c|}{Speech (\# phones)}\\
%(ISO 639-3) & Train & Dev & Eval \\ \hline\hline
%arb & 32486 & 8208 & 8191 \\
%yue & 32693 & 6860 & 8638 \\
%nld & 27314 & 6943 & 6582 \\
%hun & 29461 & 7873 & 7474 \\
%cmn & 29461 & 8244 & 7035 \\
%swh & 28571 & 7658 & 7441 \\
%urd & 21275 & 5808 & 3689 \\\hline
%\end{tabular}
%\vspace*{1mm}
%\caption{Data statistics, seven languages, \# 
%phones in the train/dev/eval sets.}
%\label{tab:data}
%\end{table}
